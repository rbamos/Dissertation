\section{Introduction}
\label{sec:intro}
Privacy policies are one of the few available lenses for understanding how businesses interact with personal information. In the modern web ecosystem, many websites rely on monetizing user engagement as a primary revenue stream, which can reveal sensitive personal information to third parties such as advertisers and data brokers. Understanding privacy policies is, consequently, crucial for understanding both user privacy and economics on the web.

In this work, we aim to make privacy policies more accessible to researchers, who can in turn make privacy policies more useful to users, regulators, journalists, and other web stakeholders. There is extensive and valuable prior empirical work on privacy policies (Section \ref{sec:related}). Our goal is to advance privacy research by improving the scale and longitudinal scope of analysis.

\textbf{Dataset.} We built a crawler that discovers, downloads, and extracts text from privacy policies archived on the Internet Archiveâ€™s Wayback Machine. We used the crawler to assemble a privacy policy dataset that spans more than two decades and consists of over one million privacy policies from over 130,000 websites. The key challenge we faced was automatically identifying privacy policy pages and distinguishing them from similar documents at scale. We solved this problem in two steps. First, we developed a set of heuristics for downloading candidate privacy policies with high recall. The heuristics were based on manual analysis of hundreds of policies across several failure and success cases of our crawler. Next, to filter out non-privacy policies, we built a random forest classifier that achieves 98\% precision and 93\% recall. We describe a number of validation and quality control steps we performed throughout this process (Sections~\ref{sec:methods},~\ref{sec:classifier}, and~\ref{sec:dataset}).

Our dataset is publicly available and has received substantial attention, with over 80 access requests from private companies, industry research labs, and academic researchers as of the time of writing. 
To make our dataset more accessible, we have built a convenient change tracking interface (with GitHub as a backend) for examining how each privacy policy has evolved over time.

\textbf{Longitudinal analysis.} We used our dataset to conduct what is, to our knowledge, the longest-spanning and largest-scale longitudinal analysis of privacy policies (Sections~\ref{sec:doclevstatstime}~and~\ref{sec:analysis}).
Much of our analysis was guided by an automated trend detection tool that we developed to identify terms and concepts that may indicate shifts in the privacy policy landscape. Our system helped us identify trends related to self-regulatory organizations, third parties, tracking technologies, and regulations.
Our findings further undermine the idea that users can reasonably make informed decisions based on the information disclosed in privacy policies.

First, we find that over the last 20 years, privacy policies have become substantially longer---with a median length of 1,522 words in 2019---and moderately less readable, with the median policy being at a college reading level. Websites that are more popular have even less readable policies.

Second, we find that more than 20\% of websites have a privacy policy that links to one or more additional privacy policies. If a user wanted to understand the set of applicable privacy policies for one of these websites, they would face an even greater burden.


Third, our results show that, when compared to empirical measurements of web privacy practices, privacy policies vastly underreport tracking technologies and third parties.

Fourth, consistent with prior work on privacy regulation, we find that the GDPR prompted the most widespread changes to privacy policies in the last decade.

Finally, we examine which self-regulatory bodies have experienced growth and which have stagnated.

Our analysis and dataset help pave the way for researchers to understand the connection between government regulation, self-regulation, and user privacy. Understanding the impacts of past actions can help drive evidence-based methods for creating effective privacy policy legislation. Our work is a step in this direction.

%A longer version of this paper with more technical details is available as a technical report.\footnote{\url{https://privacypolicies.cs.princeton.edu/techreport}}

